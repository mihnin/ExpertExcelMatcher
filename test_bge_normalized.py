# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç BGE-M3 —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏ (–∫–∞–∫ –≤ Notebook)
"""

import sys
import io

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import numpy as np
from FlagEmbedding import BGEM3FlagModel
import pandas as pd
import re
from transliterate import translit

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
# (–∫–æ–ø–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏—é normalize_string)

class NormalizationConstants:
    """–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ (–ø–æ–¥—Ö–æ–¥ –ê—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä–æ–≤)"""
    # –°—Ç–æ–ø-—Å–ª–æ–≤–∞ (—Ä—É—Å—Å–∫–∏–µ –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ)
    RU_STOP = {"–∏", "–≤", "–≤–æ", "–Ω–µ", "–Ω–∞", "–Ω–æ", "–ø—Ä–∏", "–¥–ª—è", "–∫", "–∏–∑", "–æ—Ç", "—Å", "—Å–æ", "–æ", "–∞", "—É", "–ø–æ", "–Ω–∞–¥", "–ø–æ–¥", "–¥–æ", "–±–µ–∑", "–∏–ª–∏"}
    EN_STOP = {"the", "a", "an", "and", "or", "of", "for", "in", "on", "at", "to", "from", "with", "by", "without", "into", "out", "over", "under", "above", "below"}
    STOP_WORDS = RU_STOP | EN_STOP

    # –†–µ–≥—É–ª—è—Ä–∫–∏ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º
    LEGAL_PREFIXES = [
        r'\b–û–û–û\b', r'\b–ê–û\b', r'\b–ó–ê–û\b', r'\b–ò–ü\b', r'\b–ü–ê–û\b', r'\b–ì–ö\b',
        r'\b–ù–ö–û\b', r'\b–ù–ü–û\b', r'\b–ù–ü–ü\b', r'\b–ù–ü–§\b', r'\b–û–ê–û\b',
        r'\bLtd\.?\b', r'\bLimited\b', r'\bInc\.?\b', r'\bLLC\b', r'\bGmbH\b',
        r'\bCorp\.?\b', r'\bCo\.?\b', r'\bSARL\b', r'\bS\.?A\.?\b',
        r'\bPLC\b', r'\bGroup\b', r'\bCompany\b', r'\b–ö–æ–º–ø–∞–Ω–∏—è\b',
        r'\b–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å\b',
        r'\b–û–±—â–µ—Å—Ç–≤–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω–æ–π –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é\b'
    ]

    # –í–µ—Ä—Å–∏–æ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    VERSION_PATTERNS = [
        r'\b(19|20)\d{2}\b',                    # –≥–æ–¥—ã (2019, 2021)
        r'\b[vV]\.?\d+\.[xX]\b',                # v.4.x, v4.x
        r'\b\d+\.[xX]\b',                       # 8.x
        r'\b[vV]\.?\d+(\.\d+)*[a-z]*\b',        # v.4, v4, v.1.2
        r'\b\d+\.\d+(\.\d+)*[a-z]*\b',          # 8.1, 2021.1a
        r'\bR\d+\b',                            # R2
        r'\bSP\d+\b',                           # SP1
        r'\b(x64|x86|64[-\s]?bit|32[-\s]?bit)\b',
        r'\bCC\b',                              # Adobe CC
    ]

def normalize_string(s: str,
                    remove_legal: bool = True,
                    remove_versions: bool = True,
                    remove_stopwords: bool = True,
                    transliterate_text: bool = True,
                    remove_punctuation: bool = True) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ç—Ä–æ–∫–∏"""
    if not s or pd.isna(s):
        return ""
    s = str(s).strip()

    # 1. –£–¥–∞–ª–µ–Ω–∏–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º
    if remove_legal:
        for pattern in NormalizationConstants.LEGAL_PREFIXES:
            s = re.sub(pattern, ' ', s, flags=re.IGNORECASE)

    # 2. –£–¥–∞–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π
    if remove_versions:
        for pattern in NormalizationConstants.VERSION_PATTERNS:
            s = re.sub(pattern, ' ', s, flags=re.IGNORECASE)

    # 3. Lowercase
    s = s.lower()

    # 4. –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    if remove_punctuation:
        s = re.sub(r'[^\w\s]', ' ', s)

    # 5. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
    if remove_stopwords:
        words = s.split()
        words = [w for w in words if w and w not in NormalizationConstants.STOP_WORDS]
        s = ' '.join(words)

    # 6. –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
    if transliterate_text:
        if re.search(r'[–∞-—è—ë]', s):
            try:
                s = translit(s, 'ru', reversed=True)
            except Exception:
                pass

    # 7. –û—á–∏—Å—Ç–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤
    s = re.sub(r'\s+', ' ', s).strip()

    return s

print("=" * 80)
print("–¢–ï–°–¢: BGE-M3 —Å –ø–æ–ª–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π (–∫–∞–∫ –≤ Notebook)")
print("=" * 80)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
print("\nüß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
model = BGEM3FlagModel('BAAI/bge-m3', device='cpu', use_fp16=False, normalize_embeddings=True)
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n")

# –¢–µ—Å—Ç–æ–≤—ã–µ –ø–∞—Ä—ã
test_pairs = [
    ("Microsoft Office", "MS Office"),
    ("–û–û–û 1–° –ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ 8.3", "1C Enterprise"),
    ("Adobe Photoshop CC 2019", "Photoshop"),
]

def calculate_similarity(s1, s2):
    vec1 = model.encode(s1.lower())['dense_vecs']
    vec2 = model.encode(s2.lower())['dense_vecs']
    return float(np.dot(vec1, vec2)) * 100.0

for str1, str2 in test_pairs:
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏: '{str1}' vs '{str2}'")

    # –ü–æ–ª–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è (–í–°–ï –æ–ø—Ü–∏–∏ –≤–∫–ª—é—á–µ–Ω—ã)
    norm1 = normalize_string(str1,
                            remove_legal=True,
                            remove_versions=True,
                            remove_stopwords=True,
                            transliterate_text=True,
                            remove_punctuation=True)
    norm2 = normalize_string(str2,
                            remove_legal=True,
                            remove_versions=True,
                            remove_stopwords=True,
                            transliterate_text=True,
                            remove_punctuation=True)

    print(f"  –ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: '{norm1}' vs '{norm2}'")

    if not norm1 or not norm2:
        print(f"  ‚ö†Ô∏è –ü–£–°–¢–ê–Ø –°–¢–†–û–ö–ê –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏! Score = 0")
    else:
        score = calculate_similarity(norm1, norm2)
        print(f"  BGE-M3 Score: {score:.2f}%")

    print()

print("=" * 80)
print("–í–´–í–û–î:")
print("–ï—Å–ª–∏ score > 0, –∑–Ω–∞—á–∏—Ç BGE-M3 —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ —Å—Ç—Ä–æ–∫–∞–º–∏!")
print("=" * 80)
