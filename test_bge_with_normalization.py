# -*- coding: utf-8 -*-
"""
–¢–µ—Å—Ç BGE-M3 —Å —Ä–∞–∑–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
"""

import sys
import io

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import numpy as np
from FlagEmbedding import BGEM3FlagModel
from transliterate import translit
import re

print("=" * 80)
print("–¢–ï–°–¢: –í–ª–∏—è–Ω–∏–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–∞ BGE-M3")
print("=" * 80)

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
print("\nüß† –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
model = BGEM3FlagModel('BAAI/bge-m3', device='cpu', use_fp16=False, normalize_embeddings=True)
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n")

# –¢–µ—Å—Ç–æ–≤—ã–µ –ø–∞—Ä—ã
test_pairs = [
    ("Microsoft Office", "MS Office"),
    ("–û–û–û 1–° –ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ 8.3", "1C Enterprise"),
    ("Adobe Photoshop CC 2019", "Photoshop"),
]

def calculate_similarity(s1, s2):
    vec1 = model.encode(s1)['dense_vecs']
    vec2 = model.encode(s2)['dense_vecs']
    return float(np.dot(vec1, vec2)) * 100.0

def aggressive_normalize(s):
    """–ò–º–∏—Ç–∞—Ü–∏—è –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    s = str(s).lower()

    # –£–¥–∞–ª–µ–Ω–∏–µ —é—Ä.—Ñ–æ—Ä–º
    s = re.sub(r'\b–û–û–û\b', '', s, flags=re.IGNORECASE)

    # –£–¥–∞–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π
    s = re.sub(r'\b(19|20)\d{2}\b', '', s)
    s = re.sub(r'\b[vV]\.?\d+\.?\w*\b', '', s)
    s = re.sub(r'\bCC\b', '', s)
    s = re.sub(r'\b\d+\.\d+\b', '', s)

    # –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
    s = re.sub(r'[^\w\s]', ' ', s)

    # –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è (–∫—Ä–∏—Ç–∏—á–Ω–∞—è —á–∞—Å—Ç—å!)
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–∏—Ä–∏–ª–ª–∏—Ü—É
        if any(ord(c) > 127 for c in s):
            s = translit(s, 'ru', reversed=True)
    except:
        pass

    # –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
    s = re.sub(r'\s+', ' ', s).strip()

    return s

for str1, str2 in test_pairs:
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏: '{str1}' vs '{str2}'")

    # –ë–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ lowercase)
    score1 = calculate_similarity(str1.lower(), str2.lower())
    print(f"  –ë–µ–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: {score1:.2f}%")

    # –° –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π
    norm1 = aggressive_normalize(str1)
    norm2 = aggressive_normalize(str2)
    print(f"  –ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏: '{norm1}' vs '{norm2}'")
    score2 = calculate_similarity(norm1, norm2)
    print(f"  –° –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π: {score2:.2f}%")

    diff = score1 - score2
    if diff > 10:
        print(f"  ‚ö†Ô∏è –ü–û–¢–ï–†–Ø –¢–û–ß–ù–û–°–¢–ò: -{diff:.2f}%")

    print()

print("=" * 80)
print("–í–´–í–û–î:")
print("–ï—Å–ª–∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è —Å–Ω–∏–∂–∞–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç—å, –∑–Ω–∞—á–∏—Ç BGE-M3 –ù–ï –¥–æ–ª–∂–Ω–∞")
print("–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π!")
print("=" * 80)
