# -*- coding: utf-8 -*-
"""
–ü–æ–ª–Ω—ã–π —Ç–µ—Å—Ç: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí BGE ‚Üí —Ä–µ–∑—É–ª—å—Ç–∞—Ç
"""

import sys
import io

if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

import pandas as pd
import numpy as np
from FlagEmbedding import BGEM3FlagModel
import re
from transliterate import translit

# –ö–æ–ø–∏—Ä—É–µ–º –∫–ª–∞—Å—Å NormalizationConstants
class NormalizationConstants:
    RU_STOP = {"–∏", "–≤", "–≤–æ", "–Ω–µ", "–Ω–∞", "–Ω–æ", "–ø—Ä–∏", "–¥–ª—è", "–∫", "–∏–∑", "–æ—Ç", "—Å", "—Å–æ", "–æ", "–∞", "—É", "–ø–æ", "–Ω–∞–¥", "–ø–æ–¥", "–¥–æ", "–±–µ–∑", "–∏–ª–∏"}
    EN_STOP = {"the", "a", "an", "and", "or", "of", "for", "in", "on", "at", "to", "from", "with", "by", "without", "into", "out", "over", "under", "above", "below"}
    STOP_WORDS = RU_STOP | EN_STOP

    LEGAL_PREFIXES = [
        r'\b–û–û–û\b', r'\b–ê–û\b', r'\b–ó–ê–û\b', r'\b–ò–ü\b', r'\b–ü–ê–û\b', r'\b–ì–ö\b',
        r'\b–ù–ö–û\b', r'\b–ù–ü–û\b', r'\b–ù–ü–ü\b', r'\b–ù–ü–§\b', r'\b–û–ê–û\b',
        r'\bLtd\.?\b', r'\bLimited\b', r'\bInc\.?\b', r'\bLLC\b', r'\bGmbH\b',
        r'\bCorp\.?\b', r'\bCo\.?\b', r'\bSARL\b', r'\bS\.?A\.?\b',
        r'\bPLC\b', r'\bGroup\b', r'\bCompany\b', r'\b–ö–æ–º–ø–∞–Ω–∏—è\b',
    ]

    VERSION_PATTERNS = [
        r'\b(19|20)\d{2}\b',
        r'\b[vV]\.?\d+\.[xX]\b',
        r'\b\d+\.[xX]\b',
        r'\b[vV]\.?\d+(\.\d+)*[a-z]*\b',
        r'\b\d+\.\d+(\.\d+)*[a-z]*\b',
        r'\bR\d+\b',
        r'\bSP\d+\b',
        r'\b(x64|x86|64[-\s]?bit|32[-\s]?bit)\b',
        r'\bCC\b',
    ]

# –ö–æ–ø–∏—Ä—É–µ–º –º–µ—Ç–æ–¥ normalize_string –∏–∑ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
class TestMatcher:
    def __init__(self):
        self.bge_model = None
        # –ß–µ–∫–±–æ–∫—Å—ã (–í–°–ï –≤–∫–ª—é—á–µ–Ω—ã)
        self.norm_remove_legal = True
        self.norm_remove_versions = True
        self.norm_remove_stopwords = True
        self.norm_transliterate = True
        self.norm_remove_punctuation = True

    def normalize_string(self, s: str) -> str:
        """–ö–æ–ø–∏—è –∏–∑ expert_matcher.py"""
        if not s or pd.isna(s):
            return ""
        s = str(s).strip()

        # 1. –£–¥–∞–ª–µ–Ω–∏–µ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º
        if self.norm_remove_legal:
            for pattern in NormalizationConstants.LEGAL_PREFIXES:
                s = re.sub(pattern, ' ', s, flags=re.IGNORECASE)

        # 2. –£–¥–∞–ª–µ–Ω–∏–µ –≤–µ—Ä—Å–∏–π
        if self.norm_remove_versions:
            for pattern in NormalizationConstants.VERSION_PATTERNS:
                s = re.sub(pattern, ' ', s, flags=re.IGNORECASE)

        # 3. Lowercase
        s = s.lower()

        # 4. –£–¥–∞–ª–µ–Ω–∏–µ –ø—É–Ω–∫—Ç—É–∞—Ü–∏–∏
        if self.norm_remove_punctuation:
            s = re.sub(r'[^\w\s]', ' ', s)

        # 5. –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–æ–ø-—Å–ª–æ–≤
        if self.norm_remove_stopwords:
            words = s.split()
            words = [w for w in words if w and w not in NormalizationConstants.STOP_WORDS]
            s = ' '.join(words)

        # 6. –¢—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
        if self.norm_transliterate:
            if re.search(r'[–∞-—è—ë]', s):
                try:
                    s = translit(s, 'ru', reversed=True)
                except Exception:
                    pass

        # 7. –û—á–∏—Å—Ç–∫–∞ –ø—Ä–æ–±–µ–ª–æ–≤
        s = re.sub(r'\s+', ' ', s).strip()

        return s

    def bge_cosine_similarity(self, s1: str, s2: str) -> float:
        """–ö–æ–ø–∏—è –∏–∑ expert_matcher.py"""
        if not s1 or not s2 or pd.isna(s1) or pd.isna(s2):
            return 0.0

        s1 = str(s1).strip()
        s2 = str(s2).strip()

        if not s1 or not s2:
            return 0.0

        if self.bge_model is None:
            try:
                print("  üß† –ó–∞–≥—Ä—É–∑–∫–∞ BGE-M3...")
                self.bge_model = BGEM3FlagModel(
                    'BAAI/bge-m3',
                    device='cpu',
                    use_fp16=False,
                    normalize_embeddings=True
                )
                print("  ‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            except Exception as e:
                print(f"  ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
                self.bge_model = False
                return 0.0

        if self.bge_model is False:
            return 0.0

        try:
            vec1 = self.bge_model.encode(str(s1).lower())['dense_vecs']
            vec2 = self.bge_model.encode(str(s2).lower())['dense_vecs']
            similarity = float(np.dot(vec1, vec2))
            return similarity * 100.0
        except Exception as e:
            print(f"  ‚ùå –û—à–∏–±–∫–∞: {e}")
            return 0.0

print("=" * 80)
print("–ü–û–õ–ù–´–ô –¢–ï–°–¢: –ò—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ‚Üí –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è ‚Üí BGE-M3")
print("=" * 80)

matcher = TestMatcher()

test_cases = [
    ("Microsoft Office 2021", "MS Office Professional"),
    ("–û–û–û 1–° –ü—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ 8.3 x64", "1C Enterprise"),
    ("Adobe Photoshop CC 2019", "Photoshop"),
    ("Oracle Database 19c", "Oracle DB"),
]

for original1, original2 in test_cases:
    print(f"\n{'=' * 80}")
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏:")
    print(f"  '{original1}' vs '{original2}'")

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    norm1 = matcher.normalize_string(original1)
    norm2 = matcher.normalize_string(original2)

    print(f"\n–ü–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:")
    print(f"  '{norm1}' vs '{norm2}'")

    if not norm1:
        print(f"  ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: –ü–µ—Ä–≤–∞—è —Å—Ç—Ä–æ–∫–∞ —Å—Ç–∞–ª–∞ –ü–£–°–¢–û–ô –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏!")
    if not norm2:
        print(f"  ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: –í—Ç–æ—Ä–∞—è —Å—Ç—Ä–æ–∫–∞ —Å—Ç–∞–ª–∞ –ü–£–°–¢–û–ô –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏!")

    if not norm1 or not norm2:
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç BGE-M3: 0.00% (–ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞)")
        continue

    # –í—ã–∑–æ–≤ BGE
    score = matcher.bge_cosine_similarity(norm1, norm2)
    print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç BGE-M3: {score:.2f}%")

    if score == 0:
        print("  ‚ö†Ô∏è –ü–†–û–ë–õ–ï–ú–ê: BGE –≤–µ—Ä–Ω—É–ª 0 –¥–ª—è –Ω–µ–ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫!")

print("\n" + "=" * 80)
print("–ó–ê–í–ï–†–®–ï–ù–û")
print("=" * 80)
